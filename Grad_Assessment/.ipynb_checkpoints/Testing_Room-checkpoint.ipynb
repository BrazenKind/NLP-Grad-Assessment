{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce62282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_Preprocessing import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846ae10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data(filepath):\n",
    "    \n",
    "    with open(filepath, 'r', encoding='UTF-8') as f:\n",
    "        x_toadd = []\n",
    "        x_lemmas_toadd = []\n",
    "        y_toadd = []\n",
    "        x_final = []\n",
    "        x_lemmas_final = []\n",
    "        y_final = []\n",
    "        label_IDs = {}\n",
    "        word_IDs = {}\n",
    "        \n",
    "        for line in f:\n",
    "                       \n",
    "            conllu = line.split()\n",
    "            #case: end of sentence reached\n",
    "            if len(conllu) == 0:\n",
    "                \n",
    "                #filters out one-word sentences such as links to websites\n",
    "                if len(x_toadd) == 1:\n",
    "                    x_toadd = []\n",
    "                    x_lemmas_toadd = []\n",
    "                    y_toadd = []  \n",
    "                    continue\n",
    "                    \n",
    "                x_final.append(x_toadd)\n",
    "                x_lemmas_final.append(x_lemmas_toadd)\n",
    "                y_final.append(y_toadd)\n",
    "                x_toadd = []\n",
    "                x_lemmas_toadd = []\n",
    "                y_toadd = []                \n",
    "            elif conllu[0].isnumeric():\n",
    "                word = conllu[1]\n",
    "#                 XPOS = conllu[4]\n",
    "#                 extra_tags = conllu[5].split('|')\n",
    "                label = conllu[3]\n",
    "                lemma = conllu[2]\n",
    "    \n",
    "                if label not in label_IDs.keys():\n",
    "                    label_IDs[label] = len(label_IDs) + 1\n",
    "                \n",
    "                if word not in word_IDs.keys():\n",
    "                    word_IDs[word] = len(word_IDs) + 1\n",
    "                    \n",
    "                x_toadd.append(word)\n",
    "                x_lemmas_toadd.append(lemma)\n",
    "                y_toadd.append(label)\n",
    "                \n",
    "                \n",
    "                    \n",
    "                              \n",
    "    return x_final, x_lemmas_final, y_final, label_IDs, word_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0aa510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sentences, x_lemmas, y_sentences, label_IDs, word_IDs = create_data(\"UD_English-EWT/en_ewt-ud-train.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626d0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_IDs['BOS'] = 18\n",
    "label_IDs['EOS'] = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2d84ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = Data_Preprocessing(x_data = x_sentences[:101], y_data = y_sentences[:101], x_lemmas = x_lemmas[:101], x_vocab = list(word_IDs.keys()), labels = list(label_IDs.keys()), label_dict = label_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd5aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now generating x...\n",
      "(30, 19, 19, 363)\n",
      "(19, 19, 19, 363)\n",
      "(18, 19, 19, 363)\n",
      "(17, 19, 19, 363)\n",
      "(37, 19, 19, 363)\n",
      "(14, 19, 19, 363)\n",
      "(14, 19, 19, 363)\n",
      "(17, 19, 19, 363)\n",
      "(36, 19, 19, 363)\n",
      "(21, 19, 19, 363)\n",
      "(20, 19, 19, 363)\n",
      "(30, 19, 19, 363)\n",
      "(20, 19, 19, 363)\n",
      "(18, 19, 19, 363)\n",
      "(28, 19, 19, 363)\n",
      "(27, 19, 19, 363)\n",
      "(28, 19, 19, 363)\n",
      "(12, 19, 19, 363)\n",
      "(21, 19, 19, 363)\n",
      "(10, 19, 19, 363)\n",
      "(16, 19, 19, 363)\n",
      "(17, 19, 19, 363)\n",
      "(18, 19, 19, 363)\n",
      "(41, 19, 19, 363)\n",
      "(50, 19, 19, 363)\n",
      "(52, 19, 19, 363)\n",
      "(14, 19, 19, 363)\n",
      "(11, 19, 19, 363)\n",
      "(10, 19, 19, 363)\n",
      "(31, 19, 19, 363)\n",
      "(21, 19, 19, 363)\n",
      "(27, 19, 19, 363)\n",
      "(29, 19, 19, 363)\n",
      "(17, 19, 19, 363)\n",
      "(14, 19, 19, 363)\n",
      "(13, 19, 19, 363)\n",
      "(20, 19, 19, 363)\n",
      "(27, 19, 19, 363)\n",
      "(15, 19, 19, 363)\n",
      "(8, 19, 19, 363)\n",
      "(18, 19, 19, 363)\n",
      "(22, 19, 19, 363)\n",
      "(14, 19, 19, 363)\n",
      "(23, 19, 19, 363)\n",
      "(16, 19, 19, 363)\n",
      "(47, 19, 19, 363)\n",
      "(28, 19, 19, 363)\n",
      "(29, 19, 19, 363)\n",
      "(61, 19, 19, 363)\n",
      "(21, 19, 19, 363)\n",
      "(35, 19, 19, 363)\n",
      "(67, 19, 19, 363)\n",
      "(32, 19, 19, 363)\n",
      "(68, 19, 19, 363)\n",
      "(5, 19, 19, 363)\n",
      "(49, 19, 19, 363)\n",
      "(20, 19, 19, 363)\n",
      "(30, 19, 19, 363)\n",
      "(38, 19, 19, 363)\n",
      "(43, 19, 19, 363)\n",
      "(45, 19, 19, 363)\n",
      "(14, 19, 19, 363)\n",
      "(12, 19, 19, 363)\n",
      "(71, 19, 19, 363)\n",
      "(77, 19, 19, 363)\n",
      "(24, 19, 19, 363)\n",
      "(40, 19, 19, 363)\n",
      "(3, 19, 19, 363)\n",
      "(12, 19, 19, 363)\n",
      "(14, 19, 19, 363)\n",
      "(17, 19, 19, 363)\n",
      "(48, 19, 19, 363)\n",
      "(25, 19, 19, 363)\n",
      "(43, 19, 19, 363)\n",
      "(39, 19, 19, 363)\n",
      "(7, 19, 19, 363)\n",
      "(51, 19, 19, 363)\n",
      "(34, 19, 19, 363)\n",
      "(26, 19, 19, 363)\n",
      "(6, 19, 19, 363)\n",
      "(34, 19, 19, 363)\n",
      "(33, 19, 19, 363)\n",
      "(61, 19, 19, 363)\n",
      "(25, 19, 19, 363)\n",
      "(10, 19, 19, 363)\n",
      "(20, 19, 19, 363)\n",
      "(10, 19, 19, 363)\n",
      "(13, 19, 19, 363)\n",
      "(18, 19, 19, 363)\n",
      "(5, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "(2, 19, 19, 363)\n",
      "Now generating y...\n"
     ]
    }
   ],
   "source": [
    "x_feats, y_feats = datum.generate_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1240905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.infoukes.com/history/chornobyl/gregorovich/index.html']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7b9bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3",
   "language": "python",
   "name": "tf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
