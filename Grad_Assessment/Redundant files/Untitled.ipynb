{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f5ae686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in zip([[0, 1], [1, 1], [0,1]], [1,0,1]):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33b60455",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'BOS'\n",
    "EOS = 'EOS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74b35974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b(x, i) in Intro to CRFs Hanna M. Wallach et al.\n",
    "def equivalence_func(x, i, x_seq):\n",
    "    \n",
    "    return 1 if x == x_seq[i] else 0\n",
    "\n",
    "def transition_funcs(y_prev, y, x, i, x_seq, y_seq):\n",
    "    \n",
    "    transition_encodings = []\n",
    "    \n",
    "    for y_prev in y_seq[:-1]:\n",
    "        for y in y_seq[1:]:\n",
    "            transition_encodings += equivalence_func(x, i, x_seq) if y_prev == y_seq[i-1] and y == y_seq[i] else 0\n",
    "            \n",
    "    return transition_encodings\n",
    "#     return [lambda y_prev, y, x, i, x_seq, y_seq: equivalence_func(x, i, x_seq) if y_prev == y_seq[i-1] and y == y_seq[i] else 0\n",
    "#            for y_prev in y_seq[:-1] for y in y_seq[1:]]\n",
    "    #return equivalence_func(x, i, x_seq) if y_prev == y_seq[i-1] and y == y_seq[i] else 0\n",
    "\n",
    "def state_funcs(y, x, x_lemma, i):\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    features += [1 if x_lemma is x else 0]\n",
    "    \n",
    "    return features\n",
    "\n",
    "#Generates features for a single sentence in out x dataset\n",
    "def featurize_sentence(sentence, labels, funcs):\n",
    "    \n",
    "    feature_len = len(funcs)\n",
    "    features = np.zeros(len(sentence) + 1, len(labels), len(labels), feature_len)\n",
    "    \n",
    "    for i in range(0, len(sentence) + 1):\n",
    "        for j in range(0, len(labels)):\n",
    "            for k in range(0, len(labels)):\n",
    "                for func in funcs:\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    \n",
    "\n",
    "def create_data(filepath):\n",
    "    \n",
    "    with open(filepath, 'r', encoding='UTF-8') as f:\n",
    "        x_toadd = []\n",
    "        x_lemmas_toadd = []\n",
    "        y_toadd = []\n",
    "        x_final = []\n",
    "        x_lemmas_final = []\n",
    "        y_final = []\n",
    "        label_IDs = {}\n",
    "        word_IDs = {}\n",
    "        \n",
    "        for line in f:\n",
    "                       \n",
    "            conllu = line.split()\n",
    "            #case: end of sentence reached\n",
    "            if len(conllu) == 0:\n",
    "                x_final.append(x_toadd)\n",
    "                x_lemmas_final.append(x_lemmas_toadd)\n",
    "                y_final.append(y_toadd)\n",
    "                x_toadd = []\n",
    "                x_lemmas_toadd = []\n",
    "                y_toadd = []                \n",
    "            elif conllu[0].isnumeric():\n",
    "                word = conllu[1]\n",
    "#                 XPOS = conllu[4]\n",
    "#                 extra_tags = conllu[5].split('|')\n",
    "                label = conllu[3]\n",
    "                lemma = conllu[2]\n",
    "    \n",
    "                if label not in label_IDs.keys():\n",
    "                    label_IDs[label] = len(label_IDs) + 1\n",
    "                \n",
    "                if word not in word_IDs.keys():\n",
    "                    word_IDs[word] = len(word_IDs) + 1\n",
    "                    \n",
    "                x_toadd.append(word)\n",
    "                x_lemmas_toadd.append(lemma)\n",
    "                y_toadd.append(label)\n",
    "                \n",
    "                \n",
    "                    \n",
    "                              \n",
    "    return x_final, x_lemmas_final, y_final, label_IDs, word_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "650a98d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.asarray([[1,2,3], [1,2,34]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "926ccbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'AUX',\n",
       " 'ADV',\n",
       " 'VERB',\n",
       " 'ADV',\n",
       " 'ADV',\n",
       " 'PUNCT',\n",
       " 'CCONJ',\n",
       " 'ADV',\n",
       " 'VERB',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'NOUN',\n",
       " 'PRON',\n",
       " 'ADV',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'PRON',\n",
       " 'NOUN',\n",
       " 'PUNCT',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6442bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    x_sentences, x_lemmas, y_sentences, label_IDs, word_IDs = create_data(\"UD_English-EWT/en_ewt-ud-train.conllu\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f18dbc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PROPN': 1,\n",
       " 'PUNCT': 2,\n",
       " 'ADJ': 3,\n",
       " 'NOUN': 4,\n",
       " 'VERB': 5,\n",
       " 'DET': 6,\n",
       " 'ADP': 7,\n",
       " 'AUX': 8,\n",
       " 'PRON': 9,\n",
       " 'PART': 10,\n",
       " 'SCONJ': 11,\n",
       " 'NUM': 12,\n",
       " 'ADV': 13,\n",
       " 'CCONJ': 14,\n",
       " 'X': 15,\n",
       " 'INTJ': 16,\n",
       " 'SYM': 17}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4d2a5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19672"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8533c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3",
   "language": "python",
   "name": "tf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
