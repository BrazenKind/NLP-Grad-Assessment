{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe987f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "from tensorflow import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "308a7d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Preprocessing:\n",
    "    def __init__(self, x_data, y_data, x_lemmas, x_vocab, labels, label_dict):\n",
    "        \n",
    "        #x_data: the sentence we're converting into features\n",
    "        #y_data: the labels that correspond to the sentence we're converting\n",
    "        #x_lemmas, the lemma forms of each word within the sentence we're converting\n",
    "        #x_vocab: a set containing our x vocabulary\n",
    "        #labels: a set containing our y vocabulary\n",
    "        \n",
    "        self.x = x_data\n",
    "        self.y = y_data\n",
    "        self.x_l = x_lemmas\n",
    "        self.x_v = x_vocab\n",
    "        self.l = labels\n",
    "        self.l_d = label_dict\n",
    "        \n",
    "    #the state function b(x, i) in Intro to CRFs Hanna M. Wallach et al.\n",
    "    def equivalence_func(self, x, i, x_seq):\n",
    "\n",
    "        return 1 if x == x_seq[i] else 0\n",
    "\n",
    "    def transition_funcs(self, labels):\n",
    "\n",
    "#         transition_encodings = []\n",
    "\n",
    "#         for y_prev in y_seq[:-1]:\n",
    "#             for y in y_seq[1:]:\n",
    "#                 transition_encodings += equivalence_func(x, i, x_seq) if y_prev == y_seq[i-1] and y == y_seq[i] else 0\n",
    "\n",
    "#         return transition_encodings\n",
    "\n",
    "        \n",
    "        return [lambda y_prev, y_cur, i, x, y, x_l: equivalence_func(x[i], i, x) if y_prev == y[i-1] and y_cur == y[i] else 0\n",
    "               for y_prev in labels for y_cur in labels]\n",
    "    \n",
    "        #return equivalence_func(x, i, x_seq) if y_prev == y_seq[i-1] and y == y_seq[i] else 0\n",
    "\n",
    "    def state_funcs(self):\n",
    "\n",
    "        features = []\n",
    "        \n",
    "        #feature 1: 1 if lemma form is same as base form, else 0\n",
    "        features += [lambda y_prev, y_cur, i, x, y, x_l: 1 if x_l[i] is x[i] else 0]\n",
    "        #feature 2: 1 if a numeral is present in x, else 0\n",
    "        features += [lambda y_prev, y_cur, i, x, y, x_l: 1 if re.search('[0-9]', x[i]) else 0]\n",
    "        #feature 3: a \"word/label state\" feature: a feature that says \"this word right here is a combination of this\n",
    "        #word and this label.\"\n",
    "        features += [lambda y_prev, y_cur, i, x, y, x_l, x_word = x_word, y_label = y_label: 1 if y_label == y \n",
    "                     and i < len(x) and x_word == x[i] else 0\n",
    "        for y_label in self.l\n",
    "        for x_word in self.x_v]\n",
    "        \n",
    "        return features\n",
    "\n",
    "    #Generates features for a single sentence in out x dataset\n",
    "    def featurize_sentence(self, sentence, labels, lemmas, funcs):\n",
    "\n",
    "        feature_len = len(funcs)\n",
    "        #Dimensions of our features: the amount of bigrams in our input sentence, all possible labels for n-1, all possible\n",
    "        #labels for n, the amount of feature functions for each word\n",
    "        features = np.zeros((len(sentence) + 1, len(labels), len(labels), feature_len))\n",
    "        \n",
    "        #Enumerates over all possible label sequences for each word. Added 1 to x range since we're counting bigrams\n",
    "        for i in range(0, len(sentence) + 1):\n",
    "            for j in range(0, len(self.l)):\n",
    "                for k in range(0, len(self.l)):\n",
    "                    for x in range(0, len(funcs)):\n",
    "                        features[i, j, k, x] = funcs[x](self.l[j], self.l[k], i, sentence, labels, lemmas[i])\n",
    "    \n",
    "    def featurize_labels(self, labels):\n",
    "        BOS = 'BOS'\n",
    "        EOS = 'EOS'\n",
    "        \n",
    "        labels.insert(0, BOS)\n",
    "        labels.append(EOS)\n",
    "        \n",
    "        return [self.l_d[y] if y in self.l_d.keys() else self.l_d['OOV'] for y in labels]\n",
    "    \n",
    "    def generate_features(self):\n",
    "        \n",
    "        \n",
    "        x_vals = [self.featurize_sentence(x, y, xl, [self.transition_funcs(self.l) + self.state_funcs()]) for x, y, xl in zip(self.x, self.y, self.x_l)]\n",
    "        y_vals = [self.featurize_labels(y) for y in self.y]\n",
    "        \n",
    "        return x_vals, y_vals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a63885c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22347a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3",
   "language": "python",
   "name": "tf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
