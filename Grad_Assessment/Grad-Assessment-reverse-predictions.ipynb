{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "358cb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e9c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "Directory = \"UD_English-EWT/\"\n",
    "#Order: dev, test, train\n",
    "Filename = [\"en_ewt-ud-dev.conllu\"]\n",
    "Jsons = []\n",
    "\n",
    "for f in Filename:\n",
    "    Path = \"\".join((Directory, f))\n",
    "    \n",
    "    with open(Path, 'r', encoding='UTF-8') as j:\n",
    "        i = 0\n",
    "        for line in j:\n",
    "            conllu = line.split()\n",
    "   \n",
    "    j.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b8e22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasalpha(word):\n",
    "    for x in word:\n",
    "        if x.isalpha():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def hasnumeric(word):\n",
    "    for x in word:\n",
    "        if x.isnumeric():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def hasspecial(word):\n",
    "    for x in word:\n",
    "        if x.isalnum() is False:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def create_features(filepath, tagtype):\n",
    "    \n",
    "    other_tag = 4 if tagtype == 3 else 3\n",
    "    \n",
    "    with open(filepath, 'r', encoding='UTF-8') as f:\n",
    "        x_toadd = []\n",
    "        y_toadd = []\n",
    "        x_final = []\n",
    "        y_final = []\n",
    "        \n",
    "        for line in f:\n",
    "                       \n",
    "            conllu = line.split()\n",
    "            #case: end of sentence reached\n",
    "            if len(conllu) == 0:\n",
    "                x_final.append(x_toadd)\n",
    "                y_final.append(y_toadd)\n",
    "                x_toadd = []\n",
    "                y_toadd = []                \n",
    "            elif conllu[0].isnumeric():\n",
    "                word = conllu[1]\n",
    "                #UPOS tag if we're predicting XPOS tag, XPOS tag if we're predicting UPOS tag\n",
    "                other_tag_word = conllu[other_tag]\n",
    "                other_tag_name = 'XPOS' if other_tag == 4 else 'UPOS'\n",
    "                extra_tags = conllu[5].split('|')\n",
    "                y_tag = conllu[tagtype]\n",
    "                \n",
    "                \n",
    "                features = ['bias',\n",
    "                            'word.lower=' + word.lower(),\n",
    "                            'word.%s=%s' % (other_tag_name, other_tag_word),\n",
    "                            'word.iscapitalized=%s' % word.istitle(),\n",
    "                            'word.hasnumeric=%s' % hasnumeric(word),\n",
    "                            'word.hasalpha=%s' % hasalpha(word),\n",
    "                            'word.hasspecial=%s' % hasspecial(word)\n",
    "                           ]\n",
    "#                             'word.prefix=' + word[:3],\n",
    "#                             'word.suffix=' + word[-3:]]\n",
    "                \n",
    "                if conllu[1].lower() != conllu[2].lower():\n",
    "                    features.append('word.baseform=' + conllu[2].lower())\n",
    "    \n",
    "                for x in extra_tags:\n",
    "                    if 'PronType' in x:\n",
    "                        features.append('word.prontype=' + x[9:])\n",
    "                    if 'Foreign' in x:\n",
    "                        features.append('word.foreign=' + x[8:])\n",
    "                        \n",
    "                x_toadd.append(features)\n",
    "                y_toadd.append(y_tag)\n",
    "                \n",
    "    f.close()\n",
    "                \n",
    "    return x_final, y_final\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f385a09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "#3 if predicting UPOS, 4 if predicting XPOS\n",
    "dev_x_unneighbored, dev_y = create_features(\"UD_English-EWT/en_ewt-ud-dev.conllu\", 4)\n",
    "test_x_unneighbored, test_y = create_features(\"UD_English-EWT/en_ewt-ud-test.conllu\", 4)\n",
    "train_x_unneighbored, train_y = create_features(\"UD_English-EWT/en_ewt-ud-train.conllu\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f9981b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neighbors(x_data):\n",
    "    \n",
    "    x_data_final = []\n",
    "    \n",
    "    for sentence in x_data:\n",
    "        final_sentence = []\n",
    "        for i in range(0, len(sentence)):\n",
    "            modified_word = []\n",
    "            modified_word.extend(sentence[i])\n",
    "\n",
    "            if i == 0:\n",
    "                modified_word.append('BOS')\n",
    "            else:\n",
    "                prev_word = sentence[i-1]\n",
    "                modified_word.extend(['-1:' + x for x in prev_word[1:]])\n",
    "\n",
    "            if i == (len(sentence)-1):\n",
    "                modified_word.append('EOS')\n",
    "            else:\n",
    "                next_word = sentence[i+1]\n",
    "                modified_word.extend(['+1:' + x for x in next_word[1:]])\n",
    "\n",
    "            final_sentence.append(modified_word)\n",
    "        x_data_final.append(final_sentence)\n",
    "            \n",
    "    return x_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7b5cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_x = add_neighbors(dev_x_unneighbored)\n",
    "test_x = add_neighbors(test_x_unneighbored)\n",
    "train_x = add_neighbors(train_x_unneighbored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c75ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_test():\n",
    "    for i in range(0, len(dev_y)):\n",
    "        for j in range(0,len(dev_y[i])):\n",
    "            if dev_y[i][j] == 'X':\n",
    "                print(dev_x[i][j])\n",
    "                return\n",
    "            \n",
    "x_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d19ebe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=True)\n",
    "\n",
    "for xseq, yseq in zip(train_x, train_y):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f200dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   \n",
    "    'c2': 1e-3,  \n",
    "    'max_iterations': 50,  \n",
    "\n",
    "    #'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a05e6515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 134638\n",
      "Seconds required: 0.824\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 1.000000\n",
      "c2: 0.001000\n",
      "num_memories: 6\n",
      "max_iterations: 50\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "***** Iteration #1 *****\n",
      "Loss: 671752.177676\n",
      "Feature norm: 1.000000\n",
      "Error norm: 101868.231211\n",
      "Active features: 55001\n",
      "Line search trials: 1\n",
      "Line search step: 0.000007\n",
      "Seconds required for this iteration: 3.428\n",
      "\n",
      "***** Iteration #2 *****\n",
      "Loss: 527480.038968\n",
      "Feature norm: 3.582148\n",
      "Error norm: 113745.787968\n",
      "Active features: 53497\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.688\n",
      "\n",
      "***** Iteration #3 *****\n",
      "Loss: 451148.939615\n",
      "Feature norm: 5.448802\n",
      "Error norm: 95410.591712\n",
      "Active features: 56143\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.875\n",
      "\n",
      "***** Iteration #4 *****\n",
      "Loss: 393676.767080\n",
      "Feature norm: 6.419848\n",
      "Error norm: 63201.902336\n",
      "Active features: 57604\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.695\n",
      "\n",
      "***** Iteration #5 *****\n",
      "Loss: 305168.526622\n",
      "Feature norm: 9.851806\n",
      "Error norm: 72528.071082\n",
      "Active features: 55754\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.584\n",
      "\n",
      "***** Iteration #6 *****\n",
      "Loss: 246666.124963\n",
      "Feature norm: 12.301783\n",
      "Error norm: 32665.008155\n",
      "Active features: 54826\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.493\n",
      "\n",
      "***** Iteration #7 *****\n",
      "Loss: 218150.753950\n",
      "Feature norm: 14.364554\n",
      "Error norm: 31027.009365\n",
      "Active features: 53099\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.651\n",
      "\n",
      "***** Iteration #8 *****\n",
      "Loss: 192416.636260\n",
      "Feature norm: 16.797120\n",
      "Error norm: 19166.885624\n",
      "Active features: 50271\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.587\n",
      "\n",
      "***** Iteration #9 *****\n",
      "Loss: 165562.889338\n",
      "Feature norm: 20.544857\n",
      "Error norm: 38975.292942\n",
      "Active features: 46478\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.448\n",
      "\n",
      "***** Iteration #10 *****\n",
      "Loss: 139593.578002\n",
      "Feature norm: 23.381425\n",
      "Error norm: 24315.684841\n",
      "Active features: 44730\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.501\n",
      "\n",
      "***** Iteration #11 *****\n",
      "Loss: 116651.624123\n",
      "Feature norm: 26.085285\n",
      "Error norm: 12073.823573\n",
      "Active features: 42242\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.646\n",
      "\n",
      "***** Iteration #12 *****\n",
      "Loss: 103758.635796\n",
      "Feature norm: 29.044987\n",
      "Error norm: 18481.705112\n",
      "Active features: 38813\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.681\n",
      "\n",
      "***** Iteration #13 *****\n",
      "Loss: 93639.964098\n",
      "Feature norm: 31.599919\n",
      "Error norm: 11564.054008\n",
      "Active features: 36152\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.616\n",
      "\n",
      "***** Iteration #14 *****\n",
      "Loss: 84230.450026\n",
      "Feature norm: 35.019876\n",
      "Error norm: 9228.310873\n",
      "Active features: 34472\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.746\n",
      "\n",
      "***** Iteration #15 *****\n",
      "Loss: 75430.912525\n",
      "Feature norm: 41.977802\n",
      "Error norm: 19799.359442\n",
      "Active features: 31917\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.838\n",
      "\n",
      "***** Iteration #16 *****\n",
      "Loss: 69325.494148\n",
      "Feature norm: 43.237989\n",
      "Error norm: 8948.945840\n",
      "Active features: 32123\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.813\n",
      "\n",
      "***** Iteration #17 *****\n",
      "Loss: 64794.272459\n",
      "Feature norm: 46.130176\n",
      "Error norm: 4239.023212\n",
      "Active features: 31513\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.659\n",
      "\n",
      "***** Iteration #18 *****\n",
      "Loss: 58566.475314\n",
      "Feature norm: 53.233231\n",
      "Error norm: 8622.471189\n",
      "Active features: 29881\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.661\n",
      "\n",
      "***** Iteration #19 *****\n",
      "Loss: 54984.670242\n",
      "Feature norm: 56.562739\n",
      "Error norm: 18249.475052\n",
      "Active features: 29028\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.590\n",
      "\n",
      "***** Iteration #20 *****\n",
      "Loss: 51611.149734\n",
      "Feature norm: 58.932565\n",
      "Error norm: 3244.405684\n",
      "Active features: 28797\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.510\n",
      "\n",
      "***** Iteration #21 *****\n",
      "Loss: 49408.569767\n",
      "Feature norm: 62.702497\n",
      "Error norm: 10522.849811\n",
      "Active features: 28027\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.610\n",
      "\n",
      "***** Iteration #22 *****\n",
      "Loss: 46737.799978\n",
      "Feature norm: 67.482376\n",
      "Error norm: 7506.269703\n",
      "Active features: 26932\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.644\n",
      "\n",
      "***** Iteration #23 *****\n",
      "Loss: 44230.406023\n",
      "Feature norm: 71.541035\n",
      "Error norm: 7098.112785\n",
      "Active features: 26032\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.505\n",
      "\n",
      "***** Iteration #24 *****\n",
      "Loss: 41936.635650\n",
      "Feature norm: 75.873586\n",
      "Error norm: 5352.424140\n",
      "Active features: 25120\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.618\n",
      "\n",
      "***** Iteration #25 *****\n",
      "Loss: 39674.084064\n",
      "Feature norm: 80.559081\n",
      "Error norm: 4942.946172\n",
      "Active features: 24099\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.705\n",
      "\n",
      "***** Iteration #26 *****\n",
      "Loss: 37622.227628\n",
      "Feature norm: 85.516586\n",
      "Error norm: 2961.411276\n",
      "Active features: 23315\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.876\n",
      "\n",
      "***** Iteration #27 *****\n",
      "Loss: 35705.823123\n",
      "Feature norm: 90.470113\n",
      "Error norm: 3251.406142\n",
      "Active features: 22573\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.704\n",
      "\n",
      "***** Iteration #28 *****\n",
      "Loss: 33952.246978\n",
      "Feature norm: 95.229905\n",
      "Error norm: 2256.255751\n",
      "Active features: 21814\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.701\n",
      "\n",
      "***** Iteration #29 *****\n",
      "Loss: 32347.657410\n",
      "Feature norm: 101.054779\n",
      "Error norm: 2666.434451\n",
      "Active features: 21075\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.642\n",
      "\n",
      "***** Iteration #30 *****\n",
      "Loss: 31122.922135\n",
      "Feature norm: 107.576809\n",
      "Error norm: 6453.739260\n",
      "Active features: 20224\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.479\n",
      "\n",
      "***** Iteration #31 *****\n",
      "Loss: 29914.361289\n",
      "Feature norm: 111.203485\n",
      "Error norm: 1133.355905\n",
      "Active features: 19786\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.468\n",
      "\n",
      "***** Iteration #32 *****\n",
      "Loss: 29005.483188\n",
      "Feature norm: 116.189967\n",
      "Error norm: 1696.232572\n",
      "Active features: 18917\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.470\n",
      "\n",
      "***** Iteration #33 *****\n",
      "Loss: 28239.174528\n",
      "Feature norm: 121.539068\n",
      "Error norm: 1283.392959\n",
      "Active features: 17849\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.508\n",
      "\n",
      "***** Iteration #34 *****\n",
      "Loss: 28097.807029\n",
      "Feature norm: 125.650502\n",
      "Error norm: 6307.474816\n",
      "Active features: 16429\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.500\n",
      "\n",
      "***** Iteration #35 *****\n",
      "Loss: 27318.034079\n",
      "Feature norm: 126.857919\n",
      "Error norm: 773.490444\n",
      "Active features: 16306\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.506\n",
      "\n",
      "***** Iteration #36 *****\n",
      "Loss: 27147.177073\n",
      "Feature norm: 127.694658\n",
      "Error norm: 565.592985\n",
      "Active features: 16063\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.626\n",
      "\n",
      "***** Iteration #37 *****\n",
      "Loss: 26718.505049\n",
      "Feature norm: 130.827447\n",
      "Error norm: 561.842840\n",
      "Active features: 15230\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.623\n",
      "\n",
      "***** Iteration #38 *****\n",
      "Loss: 26673.191578\n",
      "Feature norm: 132.791647\n",
      "Error norm: 4119.679602\n",
      "Active features: 14624\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 3.025\n",
      "\n",
      "***** Iteration #39 *****\n",
      "Loss: 26301.507513\n",
      "Feature norm: 134.170148\n",
      "Error norm: 1018.135365\n",
      "Active features: 14361\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.506\n",
      "\n",
      "***** Iteration #40 *****\n",
      "Loss: 26157.994121\n",
      "Feature norm: 135.113584\n",
      "Error norm: 530.277268\n",
      "Active features: 14144\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.491\n",
      "\n",
      "***** Iteration #41 *****\n",
      "Loss: 25886.146874\n",
      "Feature norm: 139.088627\n",
      "Error norm: 750.764247\n",
      "Active features: 13196\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.542\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Iteration #42 *****\n",
      "Loss: 25811.899847\n",
      "Feature norm: 139.515093\n",
      "Error norm: 910.954688\n",
      "Active features: 13182\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 3.130\n",
      "\n",
      "***** Iteration #43 *****\n",
      "Loss: 25753.060083\n",
      "Feature norm: 139.567090\n",
      "Error norm: 621.001480\n",
      "Active features: 13167\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.593\n",
      "\n",
      "***** Iteration #44 *****\n",
      "Loss: 25646.307089\n",
      "Feature norm: 139.972853\n",
      "Error norm: 339.354677\n",
      "Active features: 13012\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.630\n",
      "\n",
      "***** Iteration #45 *****\n",
      "Loss: 25514.013691\n",
      "Feature norm: 141.447733\n",
      "Error norm: 836.437230\n",
      "Active features: 12682\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.669\n",
      "\n",
      "***** Iteration #46 *****\n",
      "Loss: 25451.112235\n",
      "Feature norm: 142.295595\n",
      "Error norm: 2633.866060\n",
      "Active features: 12486\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.546\n",
      "\n",
      "***** Iteration #47 *****\n",
      "Loss: 25349.707795\n",
      "Feature norm: 142.925628\n",
      "Error norm: 736.757091\n",
      "Active features: 12407\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.504\n",
      "\n",
      "***** Iteration #48 *****\n",
      "Loss: 25269.982535\n",
      "Feature norm: 143.903381\n",
      "Error norm: 911.278116\n",
      "Active features: 12248\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.480\n",
      "\n",
      "***** Iteration #49 *****\n",
      "Loss: 25180.070452\n",
      "Feature norm: 145.121153\n",
      "Error norm: 225.307161\n",
      "Active features: 12018\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.482\n",
      "\n",
      "***** Iteration #50 *****\n",
      "Loss: 25091.266119\n",
      "Feature norm: 147.261190\n",
      "Error norm: 645.154273\n",
      "Active features: 11693\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 1.514\n",
      "\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 85.011\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 11693 (134638)\n",
      "Number of active attributes: 6348 (58703)\n",
      "Number of active labels: 50 (50)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b7fa43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x163ff2f4080>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8e99f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: WP IN NNP VBD IN PRP$ NN HYPH NN -LRB- CC RB NN -RRB- NN IN DT RB HYPH JJ NN NN .\n",
      "Correct:   WP IN NNP VBD IN PRP$ NN HYPH NN -LRB- CC RB NN -RRB- NNS IN DT RB HYPH JJ NN NN .\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_x[1]\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(example_sent)))\n",
    "print(\"Correct:  \", ' '.join(test_y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98f490ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_x, data_y):\n",
    "    scores = {}\n",
    "    tagger_2 = pycrfsuite.Tagger()\n",
    "    tagger_2.open('test')\n",
    "    \n",
    "    for i in range(0, len(data_x)):\n",
    "        predicted = tagger_2.tag(data_x[i])\n",
    "        actual = data_y[i]\n",
    "        \n",
    "        for j in range(0, len(predicted)):\n",
    "            \n",
    "            if predicted[j] not in scores.keys():\n",
    "                scores[predicted[j]] = {'TP': 0, 'FP': 0, 'FN': 0}\n",
    "            if actual[j] not in scores.keys():\n",
    "                scores[actual[j]] = {'TP': 0, 'FP': 0, 'FN': 0}\n",
    "            \n",
    "            if predicted[j] == actual[j]:\n",
    "                scores[predicted[j]]['TP'] += 1\n",
    "            else:\n",
    "                scores[predicted[j]]['FP'] += 1\n",
    "                scores[actual[j]]['FN'] += 1\n",
    "        \n",
    "    return scores\n",
    "        \n",
    "def print_evaluate(data):\n",
    "    for x in data.keys():\n",
    "        print(\"Stats for %s:\" % x)\n",
    "        metrics = data[x]\n",
    "        \n",
    "        precision = None\n",
    "        if metrics['TP'] == 0 and metrics['FP'] == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = metrics['TP']/(metrics['TP'] + metrics['FP'])\n",
    "        \n",
    "        print(\"Precision: \", precision)\n",
    "        \n",
    "        recall = None\n",
    "        if metrics['TP'] == 0 and metrics['FN'] == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = metrics['TP']/(metrics['TP'] + metrics['FN']) \n",
    "        print(\"Recall: \", recall)\n",
    "        \n",
    "        F1 = None\n",
    "        if precision == 0 and recall == 0:\n",
    "            F1 = 0\n",
    "        else:\n",
    "            F1 = 2*(precision*recall)/(precision + recall) \n",
    "        print(\"F1: \", F1)\n",
    "        print(\"Total occurences: \", sum(list(metrics.values())))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a18f1976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating dev data: \n",
      "\n",
      "Stats for IN:\n",
      "Precision:  0.9944868532654793\n",
      "Recall:  0.996600084997875\n",
      "F1:  0.9955423476968795\n",
      "dict_values([2345, 13, 8])\n",
      "Total occurences:  2366\n",
      "Stats for DT:\n",
      "Precision:  0.9989690721649485\n",
      "Recall:  0.9974266598044261\n",
      "F1:  0.9981972701519444\n",
      "dict_values([1938, 2, 5])\n",
      "Total occurences:  1945\n",
      "Stats for NNP:\n",
      "Precision:  0.975268817204301\n",
      "Recall:  0.9994490358126722\n",
      "F1:  0.9872108843537416\n",
      "dict_values([1814, 46, 1])\n",
      "Total occurences:  1861\n",
      "Stats for VBZ:\n",
      "Precision:  0.9713831478537361\n",
      "Recall:  0.953198127925117\n",
      "F1:  0.9622047244094489\n",
      "dict_values([611, 18, 30])\n",
      "Total occurences:  659\n",
      "Stats for NN:\n",
      "Precision:  0.9244704570791528\n",
      "Recall:  0.9928165219994014\n",
      "F1:  0.9574253138981095\n",
      "dict_values([3317, 271, 24])\n",
      "Total occurences:  3612\n",
      "Stats for ::\n",
      "Precision:  0.9696969696969697\n",
      "Recall:  0.9056603773584906\n",
      "F1:  0.9365853658536586\n",
      "dict_values([96, 3, 10])\n",
      "Total occurences:  109\n",
      "Stats for VBD:\n",
      "Precision:  0.8804780876494024\n",
      "Recall:  0.85\n",
      "F1:  0.8649706457925636\n",
      "dict_values([442, 60, 78])\n",
      "Total occurences:  580\n",
      "Stats for CD:\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n",
      "dict_values([378, 0, 0])\n",
      "Total occurences:  378\n",
      "Stats for NNS:\n",
      "Precision:  0.9677891654465594\n",
      "Recall:  0.710752688172043\n",
      "F1:  0.819590824550527\n",
      "dict_values([661, 22, 269])\n",
      "Total occurences:  952\n",
      "Stats for TO:\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n",
      "dict_values([359, 0, 0])\n",
      "Total occurences:  359\n",
      "Stats for VB:\n",
      "Precision:  0.8944636678200693\n",
      "Recall:  0.9215686274509803\n",
      "F1:  0.9078138718173836\n",
      "dict_values([1034, 122, 88])\n",
      "Total occurences:  1244\n",
      "Stats for VBG:\n",
      "Precision:  0.9253731343283582\n",
      "Recall:  0.8072916666666666\n",
      "F1:  0.8623087621696801\n",
      "dict_values([310, 25, 74])\n",
      "Total occurences:  409\n",
      "Stats for JJ:\n",
      "Precision:  0.986881335718545\n",
      "Recall:  0.9993961352657005\n",
      "F1:  0.993099309930993\n",
      "dict_values([1655, 22, 1])\n",
      "Total occurences:  1678\n",
      "Stats for .:\n",
      "Precision:  0.9946843853820598\n",
      "Recall:  0.9960079840319361\n",
      "F1:  0.995345744680851\n",
      "dict_values([1497, 8, 6])\n",
      "Total occurences:  1511\n",
      "Stats for HYPH:\n",
      "Precision:  0.8673469387755102\n",
      "Recall:  0.8947368421052632\n",
      "F1:  0.8808290155440415\n",
      "dict_values([85, 13, 10])\n",
      "Total occurences:  108\n",
      "Stats for ,:\n",
      "Precision:  0.973404255319149\n",
      "Recall:  0.9775641025641025\n",
      "F1:  0.9754797441364607\n",
      "dict_values([915, 25, 21])\n",
      "Total occurences:  961\n",
      "Stats for NFP:\n",
      "Precision:  0.9298245614035088\n",
      "Recall:  0.8833333333333333\n",
      "F1:  0.905982905982906\n",
      "dict_values([53, 4, 7])\n",
      "Total occurences:  64\n",
      "Stats for RB:\n",
      "Precision:  0.9885057471264368\n",
      "Recall:  0.9984520123839009\n",
      "F1:  0.9934539853677321\n",
      "dict_values([1290, 15, 2])\n",
      "Total occurences:  1307\n",
      "Stats for NNPS:\n",
      "Precision:  1.0\n",
      "Recall:  0.25806451612903225\n",
      "F1:  0.41025641025641024\n",
      "dict_values([16, 0, 46])\n",
      "Total occurences:  62\n",
      "Stats for VBN:\n",
      "Precision:  0.8015873015873016\n",
      "Recall:  0.8487394957983193\n",
      "F1:  0.8244897959183675\n",
      "dict_values([404, 100, 72])\n",
      "Total occurences:  576\n",
      "Stats for PRP:\n",
      "Precision:  0.9979865771812081\n",
      "Recall:  1.0\n",
      "F1:  0.9989922741014444\n",
      "dict_values([1487, 3, 0])\n",
      "Total occurences:  1490\n",
      "Stats for MD:\n",
      "Precision:  1.0\n",
      "Recall:  0.994413407821229\n",
      "F1:  0.9971988795518207\n",
      "dict_values([356, 0, 2])\n",
      "Total occurences:  358\n",
      "Stats for CC:\n",
      "Precision:  1.0\n",
      "Recall:  0.998719590268886\n",
      "F1:  0.9993593850096092\n",
      "dict_values([780, 0, 1])\n",
      "Total occurences:  781\n",
      "Stats for VBP:\n",
      "Precision:  0.8939393939393939\n",
      "Recall:  0.9182879377431906\n",
      "F1:  0.9059500959692898\n",
      "dict_values([708, 84, 63])\n",
      "Total occurences:  855\n",
      "Stats for PDT:\n",
      "Precision:  0.9130434782608695\n",
      "Recall:  1.0\n",
      "F1:  0.9545454545454545\n",
      "dict_values([21, 2, 0])\n",
      "Total occurences:  23\n",
      "Stats for POS:\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n",
      "dict_values([84, 0, 0])\n",
      "Total occurences:  84\n",
      "Stats for PRP$:\n",
      "Precision:  1.0\n",
      "Recall:  0.9968253968253968\n",
      "F1:  0.9984101748807631\n",
      "dict_values([314, 0, 1])\n",
      "Total occurences:  315\n",
      "Stats for EX:\n",
      "Precision:  1.0\n",
      "Recall:  0.9642857142857143\n",
      "F1:  0.9818181818181818\n",
      "dict_values([54, 0, 2])\n",
      "Total occurences:  56\n",
      "Stats for FW:\n",
      "Precision:  0.9615384615384616\n",
      "Recall:  0.8333333333333334\n",
      "F1:  0.8928571428571429\n",
      "dict_values([25, 1, 5])\n",
      "Total occurences:  31\n",
      "Stats for WRB:\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n",
      "dict_values([113, 0, 0])\n",
      "Total occurences:  113\n",
      "Stats for -LRB-:\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n",
      "dict_values([117, 0, 0])\n",
      "Total occurences:  117\n",
      "Stats for -RRB-:\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n",
      "dict_values([120, 0, 0])\n",
      "Total occurences:  120\n",
      "Stats for RBS:\n",
      "Precision:  1.0\n",
      "Recall:  0.95\n",
      "F1:  0.9743589743589743\n",
      "dict_values([19, 0, 1])\n",
      "Total occurences:  20\n",
      "Stats for WDT:\n",
      "Precision:  0.9811320754716981\n",
      "Recall:  0.9811320754716981\n",
      "F1:  0.9811320754716981\n",
      "dict_values([104, 2, 2])\n",
      "Total occurences:  108\n",
      "Stats for WP:\n",
      "Precision:  0.9826086956521739\n",
      "Recall:  1.0\n",
      "F1:  0.9912280701754386\n",
      "dict_values([113, 2, 0])\n",
      "Total occurences:  115\n",
      "Stats for RP:\n",
      "Precision:  0.8939393939393939\n",
      "Recall:  0.7866666666666666\n",
      "F1:  0.8368794326241135\n",
      "dict_values([59, 7, 16])\n",
      "Total occurences:  82\n",
      "Stats for WP$:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 2])\n",
      "Total occurences:  2\n",
      "Stats for ``:\n",
      "Precision:  0.875\n",
      "Recall:  0.9230769230769231\n",
      "F1:  0.8983957219251337\n",
      "dict_values([84, 12, 7])\n",
      "Total occurences:  103\n",
      "Stats for '':\n",
      "Precision:  0.9166666666666666\n",
      "Recall:  0.875\n",
      "F1:  0.8953488372093024\n",
      "dict_values([77, 7, 11])\n",
      "Total occurences:  95\n",
      "Stats for JJS:\n",
      "Precision:  0.9857142857142858\n",
      "Recall:  0.8214285714285714\n",
      "F1:  0.8961038961038961\n",
      "dict_values([69, 1, 15])\n",
      "Total occurences:  85\n",
      "Stats for JJR:\n",
      "Precision:  0.975609756097561\n",
      "Recall:  0.851063829787234\n",
      "F1:  0.9090909090909092\n",
      "dict_values([40, 1, 7])\n",
      "Total occurences:  48\n",
      "Stats for RBR:\n",
      "Precision:  0.875\n",
      "Recall:  0.6363636363636364\n",
      "F1:  0.7368421052631579\n",
      "dict_values([14, 2, 8])\n",
      "Total occurences:  24\n",
      "Stats for UH:\n",
      "Precision:  1.0\n",
      "Recall:  0.9913793103448276\n",
      "F1:  0.9956709956709957\n",
      "dict_values([115, 0, 1])\n",
      "Total occurences:  116\n",
      "Stats for $:\n",
      "Precision:  1.0\n",
      "Recall:  0.9285714285714286\n",
      "F1:  0.962962962962963\n",
      "dict_values([13, 0, 1])\n",
      "Total occurences:  14\n",
      "Stats for SYM:\n",
      "Precision:  0.7272727272727273\n",
      "Recall:  0.8\n",
      "F1:  0.761904761904762\n",
      "dict_values([16, 6, 4])\n",
      "Total occurences:  26\n",
      "Stats for GW:\n",
      "Precision:  0.7948717948717948\n",
      "Recall:  0.96875\n",
      "F1:  0.8732394366197183\n",
      "dict_values([31, 8, 1])\n",
      "Total occurences:  40\n",
      "Stats for ADD:\n",
      "Precision:  0.963855421686747\n",
      "Recall:  0.9876543209876543\n",
      "F1:  0.975609756097561\n",
      "dict_values([80, 3, 1])\n",
      "Total occurences:  84\n",
      "Stats for AFX:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 4])\n",
      "Total occurences:  4\n",
      "Stats for XX:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 3])\n",
      "Total occurences:  3\n",
      "Stats for LS:\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n",
      "dict_values([5, 0, 0])\n",
      "Total occurences:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Now evaluating dev data: \")\n",
    "print()\n",
    "results = evaluate(dev_x, dev_y)\n",
    "print_evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69af6daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating test data: \n",
      "\n",
      "Stats for PRON:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 2093, 0])\n",
      "Total occurences:  2093\n",
      "Stats for WP:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 93])\n",
      "Total occurences:  93\n",
      "Stats for X:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 10827, 0])\n",
      "Total occurences:  10827\n",
      "Stats for IN:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 2314])\n",
      "Total occurences:  2314\n",
      "Stats for NNP:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 1998])\n",
      "Total occurences:  1998\n",
      "Stats for VBD:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 529])\n",
      "Total occurences:  529\n",
      "Stats for .:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 1451])\n",
      "Total occurences:  1451\n",
      "Stats for SCONJ:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 237, 0])\n",
      "Total occurences:  237\n",
      "Stats for PROPN:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 779, 0])\n",
      "Total occurences:  779\n",
      "Stats for ADP:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 1252, 0])\n",
      "Total occurences:  1252\n",
      "Stats for PRP$:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 329])\n",
      "Total occurences:  329\n",
      "Stats for NN:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 3317])\n",
      "Total occurences:  3317\n",
      "Stats for HYPH:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 98])\n",
      "Total occurences:  98\n",
      "Stats for -LRB-:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 114])\n",
      "Total occurences:  114\n",
      "Stats for CC:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 738])\n",
      "Total occurences:  738\n",
      "Stats for RB:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 1272])\n",
      "Total occurences:  1272\n",
      "Stats for -RRB-:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 114])\n",
      "Total occurences:  114\n",
      "Stats for NNS:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 905])\n",
      "Total occurences:  905\n",
      "Stats for DET:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 1819, 0])\n",
      "Total occurences:  1819\n",
      "Stats for DT:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 1952])\n",
      "Total occurences:  1952\n",
      "Stats for ADJ:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 690, 0])\n",
      "Total occurences:  690\n",
      "Stats for JJ:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 1564])\n",
      "Total occurences:  1564\n",
      "Stats for PUNCT:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 939, 0])\n",
      "Total occurences:  939\n",
      "Stats for CCONJ:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 487, 0])\n",
      "Total occurences:  487\n",
      "Stats for NOUN:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 2076, 0])\n",
      "Total occurences:  2076\n",
      "Stats for ,:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 980])\n",
      "Total occurences:  980\n",
      "Stats for VBZ:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 578])\n",
      "Total occurences:  578\n",
      "Stats for ADV:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 563, 0])\n",
      "Total occurences:  563\n",
      "Stats for WRB:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 90])\n",
      "Total occurences:  90\n",
      "Stats for AUX:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 1288, 0])\n",
      "Total occurences:  1288\n",
      "Stats for POS:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 72])\n",
      "Total occurences:  72\n",
      "Stats for MD:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 400])\n",
      "Total occurences:  400\n",
      "Stats for VB:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 1128])\n",
      "Total occurences:  1128\n",
      "Stats for WDT:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 111])\n",
      "Total occurences:  111\n",
      "Stats for PRP:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 1426])\n",
      "Total occurences:  1426\n",
      "Stats for VBP:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 719])\n",
      "Total occurences:  719\n",
      "Stats for VERB:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 1507, 0])\n",
      "Total occurences:  1507\n",
      "Stats for VBN:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 452])\n",
      "Total occurences:  452\n",
      "Stats for VBG:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 342])\n",
      "Total occurences:  342\n",
      "Stats for PART:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 326, 0])\n",
      "Total occurences:  326\n",
      "Stats for RP:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 92])\n",
      "Total occurences:  92\n",
      "Stats for TO:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 375])\n",
      "Total occurences:  375\n",
      "Stats for NUM:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 83, 0])\n",
      "Total occurences:  83\n",
      "Stats for CD:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 536])\n",
      "Total occurences:  536\n",
      "Stats for RBS:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 20])\n",
      "Total occurences:  20\n",
      "Stats for EX:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 48])\n",
      "Total occurences:  48\n",
      "Stats for NNPS:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 78])\n",
      "Total occurences:  78\n",
      "Stats for ``:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 89])\n",
      "Total occurences:  89\n",
      "Stats for '':\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 88])\n",
      "Total occurences:  88\n",
      "Stats for ADD:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 97])\n",
      "Total occurences:  97\n",
      "Stats for SYM:\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 13, 21])\n",
      "Total occurences:  34\n",
      "Stats for ::\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 100])\n",
      "Total occurences:  100\n",
      "Stats for JJS:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 82])\n",
      "Total occurences:  82\n",
      "Stats for RBR:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 26])\n",
      "Total occurences:  26\n",
      "Stats for INTJ:\n",
      "Precision:  0.0\n",
      "Recall:  0\n",
      "F1:  0\n",
      "dict_values([0, 117, 0])\n",
      "Total occurences:  117\n",
      "Stats for UH:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 118])\n",
      "Total occurences:  118\n",
      "Stats for FW:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 13])\n",
      "Total occurences:  13\n",
      "Stats for NFP:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 103])\n",
      "Total occurences:  103\n",
      "Stats for JJR:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 46])\n",
      "Total occurences:  46\n",
      "Stats for PDT:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 19])\n",
      "Total occurences:  19\n",
      "Stats for $:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 30])\n",
      "Total occurences:  30\n",
      "Stats for GW:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 20])\n",
      "Total occurences:  20\n",
      "Stats for LS:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 3])\n",
      "Total occurences:  3\n",
      "Stats for AFX:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 5])\n",
      "Total occurences:  5\n",
      "Stats for XX:\n",
      "Precision:  0\n",
      "Recall:  0.0\n",
      "F1:  0\n",
      "dict_values([0, 0, 1])\n",
      "Total occurences:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Now evaluating test data: \")\n",
    "print()\n",
    "results = evaluate(test_x, test_y)\n",
    "print_evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eefd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3",
   "language": "python",
   "name": "tf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
